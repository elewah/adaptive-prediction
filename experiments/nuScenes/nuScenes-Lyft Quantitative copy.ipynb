{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Adaptive Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import trajectron.visualization as visualization\n",
    "import trajdata.visualization.vis as trajdata_vis\n",
    "\n",
    "from torch import optim, nn\n",
    "from torch.utils import data\n",
    "from trajdata.data_structures.data_index import AgentDataIndex\n",
    "from tqdm.notebook import tqdm\n",
    "from trajectron.model.model_registrar import ModelRegistrar\n",
    "from trajectron.model.model_utils import UpdateMode\n",
    "from trajectron.model.trajectron import Trajectron\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, Final, List, Optional\n",
    "from trajdata import UnifiedDataset, AgentType, AgentBatch\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to suit your computing environment and folder structure!\n",
    "\n",
    "# TRAJDATA_CACHE_DIR: Final[str] = \"/home/bivanovic/.unified_data_cache\"\n",
    "# LYFT_SAMPLE_RAW_DATA_DIR: Final[str] = \"/home/bivanovic/datasets/lyft/scenes/sample.zarr\"\n",
    "\n",
    "TRAJDATA_CACHE_DIR: Final[str] = \"/home/iot-lab/.unified_data_cache\"\n",
    "LYFT_SAMPLE_RAW_DATA_DIR: Final[str] = \"/home/iot-lab/datasets/nuScenes\"\n",
    "sample_type=\"nusc_mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"models/nusc_mm_base_tpp-11_Sep_2022_19_15_45\"\n",
    "k0_model = \"models/nusc_mm_k0_tpp-12_Sep_2022_00_40_16\"\n",
    "adaptive_model = \"models/nusc_mm_sec4_tpp-13_Sep_2022_11_06_01\"\n",
    "oracle_model = \"models/lyft_mm_base_tpp-11_Sep_2022_18_56_49\"\n",
    "\n",
    "base_checkpoint = 20\n",
    "k0_checkpoint = 20\n",
    "adaptive_checkpoint = 20\n",
    "oracle_checkpoint = 1\n",
    "\n",
    "eval_data = \"nusc_mini-mini_val\"\n",
    "\n",
    "history_sec = 1.0\n",
    "prediction_sec = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AXHLINE_COLORS = {\n",
    "    \"Base\": \"#DD9787\",\n",
    "    \"K0\": \"#A6C48A\",\n",
    "    \"Oracle\": \"#BCB6FF\"\n",
    "}\n",
    "\n",
    "SEABORN_PALETTE = {\n",
    "    \"Finetune\": \"#AA7C85\",\n",
    "    \"K0+Finetune\": \"#2D93AD\",\n",
    "    \"Ours\": \"#67934D\",\n",
    "    \"Ours+Finetune\": \"#FF8E61\",\n",
    "    \"Base\": \"#DD9787\",\n",
    "    \"K0\": \"#A6C48A\",\n",
    "    \"Oracle\": \"#BCB6FF\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir: str, device: str, epoch: int = 10, custom_hyperparams: Optional[Dict] = None):\n",
    "    save_path = Path(model_dir) / f'model_registrar-{epoch}.pt'\n",
    "\n",
    "    model_registrar = ModelRegistrar(model_dir, device)\n",
    "    with open(os.path.join(model_dir, 'config.json'), 'r') as config_json:\n",
    "        hyperparams = json.load(config_json)\n",
    "        \n",
    "    if custom_hyperparams is not None:\n",
    "        hyperparams.update(custom_hyperparams)\n",
    "\n",
    "    trajectron = Trajectron(model_registrar, hyperparams, None, device)\n",
    "    trajectron.set_environment()\n",
    "    trajectron.set_annealing_params()\n",
    "\n",
    "    checkpoint = torch.load(save_path, map_location=device)\n",
    "    trajectron.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "\n",
    "    return trajectron, hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_to_predchal(\n",
    "    dataset: UnifiedDataset,\n",
    "    split: str\n",
    ") -> None:\n",
    "    with open(f'predchal_{split}_index.pkl','rb') as f:\n",
    "        within_challenge_split = pickle.load(f)\n",
    "    \n",
    "    within_challenge_split = [\n",
    "        (dataset.cache_path / scene_info_path, num_elems, elems)\n",
    "        for scene_info_path, num_elems, elems in within_challenge_split\n",
    "    ]\n",
    "    \n",
    "    dataset._scene_index = [orig_path for orig_path, _, _ in within_challenge_split]\n",
    "\n",
    "    # The data index is effectively a big list of tuples taking the form:\n",
    "    # (scene_path: str, index_len: int, valid_timesteps: np.ndarray[, agent_name: str])\n",
    "    dataset._data_index = AgentDataIndex(within_challenge_split, dataset.verbose)\n",
    "    dataset._data_len: int = len(dataset._data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_update(model: Trajectron, batch: AgentBatch = None, dataloader: data.DataLoader = None, num_epochs: int = None, update_mode: UpdateMode = UpdateMode.NO_UPDATE) -> float:\n",
    "    if batch is None and dataloader is None:\n",
    "        raise ValueError(\"Only one of batch or dataloader can be passed in.\")\n",
    "    \n",
    "    if dataloader is not None and num_epochs is None:\n",
    "        raise ValueError(\"num_epochs must not be None if dataloader is not None.\")\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    optimizer = optim.Adam([{'params': model.model_registrar.get_all_but_name_match('map_encoder').parameters()},\n",
    "                            {'params': model.model_registrar.get_name_match('map_encoder').parameters(),\n",
    "                             'lr': model.hyperparams['map_enc_learning_rate']/10}],\n",
    "                           lr=model.hyperparams['learning_rate']/10)\n",
    "    # Set Learning Rate\n",
    "    if model.hyperparams['learning_rate_style'] == 'const':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.0)\n",
    "    elif model.hyperparams['learning_rate_style'] == 'exp':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                        gamma=model.hyperparams['learning_decay_rate'])\n",
    "    \n",
    "    if batch is not None:\n",
    "        model.step_annealers()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        train_loss = model(batch, update_mode=update_mode)\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Clipping gradients.\n",
    "        if model.hyperparams['grad_clip'] is not None:\n",
    "            nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Stepping forward the learning rate scheduler and annealers.\n",
    "        lr_scheduler.step()\n",
    "    \n",
    "    elif dataloader is not None:\n",
    "        batch: AgentBatch\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            model.step_annealers()\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            train_loss = model(batch)\n",
    "                        \n",
    "            train_loss.backward()\n",
    "\n",
    "            # Clipping gradients.\n",
    "            if model.hyperparams['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Stepping forward the learning rate scheduler and annealers.\n",
    "            lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_last_layer_update(model: Trajectron, batch: AgentBatch = None, dataloader: data.DataLoader = None, num_epochs: int = None) -> float:\n",
    "    if batch is None and dataloader is None:\n",
    "        raise ValueError(\"Only one of batch or dataloader can be passed in.\")\n",
    "    \n",
    "    if dataloader is not None and num_epochs is None:\n",
    "        raise ValueError(\"num_epochs must not be None if dataloader is not None.\")\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    optimizer = optim.Adam([{'params': model.model_registrar.get_all_but_name_match('last_layer').parameters()},\n",
    "                            {'params': model.model_registrar.get_name_match('last_layer').parameters(),\n",
    "                             'lr': model.hyperparams['learning_rate']/10}],\n",
    "                           lr=0)\n",
    "    # Set Learning Rate\n",
    "    if model.hyperparams['learning_rate_style'] == 'const':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.0)\n",
    "    elif model.hyperparams['learning_rate_style'] == 'exp':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                        gamma=model.hyperparams['learning_decay_rate'])\n",
    "    \n",
    "    if batch is not None:\n",
    "        model.step_annealers()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        train_loss = model(batch)\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Clipping gradients.\n",
    "        if model.hyperparams['grad_clip'] is not None:\n",
    "            nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Stepping forward the learning rate scheduler and annealers.\n",
    "        lr_scheduler.step()\n",
    "            \n",
    "    elif dataloader is not None:\n",
    "        batch: AgentBatch\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            model.step_annealers()\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            train_loss = model(batch)\n",
    "                        \n",
    "            train_loss.backward()\n",
    "\n",
    "            # Clipping gradients.\n",
    "            if model.hyperparams['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Stepping forward the learning rate scheduler and annealers.\n",
    "            lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['nusc_mini-mini_val-boston', 'singapore-nusc_mini-mini_val']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Agent Data (Serially): 100%|██████████| 2/2 [00:00<00:00, 3501.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|██████████| 2/2 [00:00<00:00, 513.16it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 2/2 [00:00<00:00, 2106.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['nusc_mini-mini_val-boston', 'singapore-nusc_mini-mini_val']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Agent Data (Serially): 100%|██████████| 2/2 [00:00<00:00, 8971.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|██████████| 2/2 [00:00<00:00, 583.03it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 2/2 [00:00<00:00, 1470.14it/s]\n"
     ]
    }
   ],
   "source": [
    "adaptive_trajectron, hyperparams = load_model(\n",
    "    adaptive_model, device, epoch=adaptive_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": True}\n",
    ")\n",
    "# For offline test\n",
    "adaptive_finetune_trajectron, _ = load_model(\n",
    "    adaptive_model, device, epoch=adaptive_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": True}\n",
    ")\n",
    "\n",
    "\n",
    "k0_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "k0_finetune_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "base_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "finetune_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "oracle_trajectron, _ = load_model(oracle_model, device, epoch=oracle_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "# Load training and evaluation environments and scenes\n",
    "attention_radius = defaultdict(lambda: 20.0) # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 10.0\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.VEHICLE)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.PEDESTRIAN)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.VEHICLE)] = 30.0\n",
    "\n",
    "map_params = {\"px_per_m\": 2, \"map_size_px\": 100, \"offset_frac_xy\": (-0.75, 0.0)}\n",
    "\n",
    "online_eval_dataset = UnifiedDataset(\n",
    "    desired_data=[eval_data],\n",
    "    history_sec=(0.1, history_sec),\n",
    "    future_sec=(prediction_sec, prediction_sec),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams['incl_robot_node'],\n",
    "    incl_raster_map=hyperparams['map_encoding'],\n",
    "    raster_map_params=map_params,\n",
    "    only_predict=[AgentType.VEHICLE],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=0,\n",
    "    cache_location=TRAJDATA_CACHE_DIR,\n",
    "    data_dirs={\n",
    "        sample_type: LYFT_SAMPLE_RAW_DATA_DIR,\n",
    "    },\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "batch_eval_dataset = UnifiedDataset(\n",
    "    desired_data=[eval_data],\n",
    "    history_sec=(history_sec, history_sec),\n",
    "    future_sec=(prediction_sec, prediction_sec),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams['incl_robot_node'],\n",
    "    incl_raster_map=hyperparams['map_encoding'],\n",
    "    raster_map_params=map_params,\n",
    "    only_predict=[AgentType.VEHICLE],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=0,\n",
    "    cache_location=TRAJDATA_CACHE_DIR,\n",
    "    data_dirs={\n",
    "        sample_type: \"\",\n",
    "    },\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = re.compile(\"(.*)/(?P<scene_name>.*)/(.*)$\")\n",
    "\n",
    "def plot_outputs(\n",
    "    eval_dataset: UnifiedDataset,\n",
    "    dataset_idx: int,\n",
    "    model: Trajectron,\n",
    "    model_name: str,\n",
    "    agent_ts: int,\n",
    "    save=True,\n",
    "    extra_str=None,\n",
    "    subfolder=\"\",\n",
    "    filetype=\"png\"\n",
    "):\n",
    "    batch: AgentBatch = eval_dataset.get_collate_fn(pad_format=\"right\")([eval_dataset[dataset_idx]])\n",
    "    with torch.no_grad():\n",
    "        # predictions = model.predict(batch,\n",
    "        #                             z_mode=True,\n",
    "        #                             gmm_mode=True,\n",
    "        #                             full_dist=False,\n",
    "        #                             output_dists=False)\n",
    "        # prediction = next(iter(predictions.values()))\n",
    "        \n",
    "        pred_dists, _ = model.predict(batch,\n",
    "                                      z_mode=False,\n",
    "                                      gmm_mode=False,\n",
    "                                      full_dist=True,\n",
    "                                      output_dists=True)\n",
    "        # pred_dist = next(iter(pred_dists.values()))\n",
    "        \n",
    "    batch.to(\"cpu\")\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    trajdata_vis.plot_agent_batch(batch, batch_idx=0, ax=ax, show=False, close=False)\n",
    "    visualization.visualize_distribution(ax, pred_dists, batch_idx=0)\n",
    "    \n",
    "    # batch_eval: Dict[str, torch.Tensor] = evaluation.compute_batch_statistics_pt(\n",
    "    #     batch.agent_fut[..., :2],\n",
    "    #     prediction_output_dict=torch.from_numpy(prediction),\n",
    "    #     y_dists=pred_dist\n",
    "    # )\n",
    "    \n",
    "    scene_info_path, _, scene_ts = eval_dataset._data_index[dataset_idx]\n",
    "    scene_name = prog.match(scene_info_path).group(\"scene_name\")\n",
    "    \n",
    "    agent_name = batch.agent_name[0]\n",
    "    agent_type_name = f\"{str(AgentType(batch.agent_type[0].item()))}/{agent_name}\"\n",
    "    \n",
    "    ax.set_title(f\"{scene_name}/t={scene_ts} {agent_type_name}\")\n",
    "    # print(model_name, extra_str, batch_eval)\n",
    "    \n",
    "    if save:\n",
    "        fname = f\"plots/{subfolder}{model_name}_{scene_name}_{agent_name}_t{agent_ts}\"\n",
    "        if extra_str:\n",
    "            fname += \"_\" + extra_str\n",
    "        fig.savefig(fname + f\".{filetype}\")\n",
    "        \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(\n",
    "    eval_dataset: UnifiedDataset,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 0,\n",
    "    shuffle: bool = False\n",
    "):\n",
    "    return data.DataLoader(\n",
    "        eval_dataset,\n",
    "        collate_fn=eval_dataset.get_collate_fn(pad_format=\"right\"),\n",
    "        pin_memory=False if device == 'cpu' else True,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [\"ml_ade\", \"ml_fde\", \"nll_mean\", \"min_ade_5\", \"min_ade_10\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Online (Per-Agent) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_results_to_summary(\n",
    "    model_name: str,\n",
    "    overall_summary_dict: Dict[str, List[float]],\n",
    "    model_perf_dict: Dict[AgentType, Dict[str, np.ndarray]]\n",
    "):\n",
    "    overall_summary_dict[\"model\"].append(model_name)\n",
    "    for metric in metrics_list:\n",
    "        overall_summary_dict[metric].append(np.mean(np.concatenate(model_perf_dict[AgentType.VEHICLE][metric])).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005700349807739258,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval Base",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbe141ade294c159693e8daf5d76b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Base:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005858182907104492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval K0",
       "rate": null,
       "total": 34,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f46b19537ab46ce81688fe12d1145e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval K0:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004590749740600586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Eval Oracle",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54fbed9964f455c975607556cac131a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Oracle:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dict = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Base Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=16)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval Base'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = base_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "    \n",
    "    add_results_to_summary(\"Base\", eval_dict, model_perf)\n",
    "    \n",
    "    # K0 Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, batch_size=64, num_workers=8)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval K0'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = k0_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "                \n",
    "    add_results_to_summary(\"K0\", eval_dict, model_perf)\n",
    "    \n",
    "    # Oracle Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval Oracle'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = oracle_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "                \n",
    "    add_results_to_summary(\"Oracle\", eval_dict, model_perf)\n",
    "    \n",
    "    del eval_batch\n",
    "    del eval_results\n",
    "    del model_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'model': ['Base', 'K0', 'Oracle'],\n",
       "             'ml_ade': [0.7199507355690002,\n",
       "              0.26259008049964905,\n",
       "              0.4440161883831024],\n",
       "             'ml_fde': [1.3890087604522705,\n",
       "              0.481600821018219,\n",
       "              0.7074191570281982],\n",
       "             'nll_mean': [-1.3222638368606567,\n",
       "              0.5856841206550598,\n",
       "              -1.7169257402420044],\n",
       "             'min_ade_5': [0.1929401159286499,\n",
       "              0.16462832689285278,\n",
       "              0.42212653160095215],\n",
       "             'min_ade_10': [0.1210647001862526,\n",
       "              0.13454264402389526,\n",
       "              0.4155721068382263]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/base_performance.pkl\", 'wb') as f:\n",
    "    pickle.dump(eval_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/base_performance.pkl\", 'rb') as f:\n",
    "    eval_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'model': ['Base', 'K0', 'Oracle'],\n",
       "             'ml_ade': [0.7199507355690002,\n",
       "              0.26259008049964905,\n",
       "              0.4440161883831024],\n",
       "             'ml_fde': [1.3890087604522705,\n",
       "              0.481600821018219,\n",
       "              0.7074191570281982],\n",
       "             'nll_mean': [-1.3222638368606567,\n",
       "              0.5856841206550598,\n",
       "              -1.7169257402420044],\n",
       "             'min_ade_5': [0.1929401159286499,\n",
       "              0.16462832689285278,\n",
       "              0.42212653160095215],\n",
       "             'min_ade_10': [0.1210647001862526,\n",
       "              0.13454264402389526,\n",
       "              0.4155721068382263]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_calibration_values(model: Trajectron, dataloader: data.DataLoader):\n",
    "    est_probs = list()\n",
    "    \n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        batch.to(model.device)\n",
    "        \n",
    "        node_type: AgentType\n",
    "        for node_type in batch.agent_types():\n",
    "            mgcvae = model.node_models_dict[node_type.name]\n",
    "\n",
    "            agent_type_batch = batch.for_agent_type(node_type)\n",
    "            ph = agent_type_batch.agent_fut.shape[1]\n",
    "\n",
    "            # Run forward pass\n",
    "            y_dists, _ = mgcvae.predict(agent_type_batch,\n",
    "                                        prediction_horizon=ph,\n",
    "                                        num_samples=1,\n",
    "                                        z_mode=False,\n",
    "                                        gmm_mode=False,\n",
    "                                        full_dist=True,\n",
    "                                        output_dists=True)\n",
    "            \n",
    "            estimated_prob = y_dists.quantile(batch.agent_fut[..., :2])\n",
    "            est_probs.extend(estimated_prob.flatten().tolist())\n",
    "    \n",
    "    return np.asarray(est_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003793001174926758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc30076f7ad4443fb1dbbdc3c865d828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005709409713745117,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434fb6a306c348c682de8c096506d8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0062024593353271484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3a7f95cc7e450c92c8c3541d835ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calib_values = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    base_calib = compute_calibration_values(base_trajectron, get_dataloader(batch_eval_dataset, num_workers=16))\n",
    "\n",
    "    batch_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "    k0_calib = compute_calibration_values(k0_trajectron, batch_dataloader)\n",
    "    oracle_calib = compute_calibration_values(oracle_trajectron, batch_dataloader)\n",
    "\n",
    "calib_values.append((0, base_calib, k0_calib, oracle_calib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_plot(est_gt_probs: np.ndarray, method_name: str, ax):\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    \n",
    "    num_gt_points = est_gt_probs.shape[0]\n",
    "    # Commenting this out, although it could be used to scale to the max PDF height.\n",
    "    # No need though, without it we can see overconfidence easier.\n",
    "    # max_pdf = est_gt_probs.max()\n",
    "    \n",
    "    fraction_gt_included = [(est_gt_probs >= threshold).sum() / num_gt_points for threshold in thresholds]\n",
    "    \n",
    "    ax.plot(thresholds, fraction_gt_included, label=method_name, lw=3, c=SEABORN_PALETTE[method_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_calibration_plots(base_calib, k0_calib, oracle_calib, ours_calib, ours_finetune_calib, finetune_calib, k0_finetune_calib, num_updates):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot([0, 1], [1, 0], label=\"Ideal\", ls=\"--\", c=\"k\")\n",
    "\n",
    "    calibration_plot(base_calib, \"Base\", ax)\n",
    "    calibration_plot(k0_calib, \"K0\", ax)\n",
    "    calibration_plot(oracle_calib, \"Oracle\", ax)\n",
    "    calibration_plot(ours_finetune_calib, \"Ours+Finetune\", ax)\n",
    "    calibration_plot(ours_calib, \"Ours\", ax)\n",
    "    calibration_plot(finetune_calib, \"Finetune\", ax)\n",
    "    calibration_plot(k0_finetune_calib, \"K0+Finetune\", ax)\n",
    "\n",
    "    ax.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0)\n",
    "    ax.set_xlabel(\"Probability Threshold\")\n",
    "    ax.set_ylabel(\"Fraction of GT Points\")\n",
    "\n",
    "    ax.grid(False)\n",
    "    \n",
    "    # fig.savefig(f\"results/calib_after{num_updates}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003859996795654297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Adaptive Eval PH=2.0",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cee964cc0454f0aadf8b1ff0965992c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adaptive Eval PH=2.0:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018755197525024414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09551d9322f5463db766acae7dda0ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004301786422729492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427973b35792472ba94bf7f48e81a5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0051822662353515625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b25671f4cdc468fa3b08129dc8c1525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "online_eval_dataloader = get_dataloader(online_eval_dataset, batch_size=1, shuffle=True)\n",
    "batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "\n",
    "adaptive_trajectron.reset_adaptive_info()\n",
    "adaptive_finetune_trajectron.reset_adaptive_info()\n",
    "\n",
    "# Resetting the finetune baselines to their base.\n",
    "finetune_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "k0_finetune_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "N_SAMPLES = 10\n",
    "\n",
    "outer_pbar = tqdm(\n",
    "    online_eval_dataloader,\n",
    "    total=min(N_SAMPLES, len(online_eval_dataloader)),\n",
    "    desc=f'Adaptive Eval PH={prediction_sec}',\n",
    "    position=0,\n",
    ")\n",
    "\n",
    "plot_per_eval = False\n",
    "\n",
    "online_batch: AgentBatch\n",
    "for data_sample, online_batch in enumerate(outer_pbar):\n",
    "    if data_sample >= N_SAMPLES:\n",
    "        outer_pbar.close()\n",
    "        break\n",
    "    \n",
    "    if data_sample == 0:\n",
    "        ours_calib = compute_calibration_values(adaptive_trajectron, batch_eval_dataloader)\n",
    "        finetune_calib = compute_calibration_values(finetune_trajectron, batch_eval_dataloader)\n",
    "        k0_finetune_calib = compute_calibration_values(k0_finetune_trajectron, batch_eval_dataloader)\n",
    "        \n",
    "        calib_values.append((data_sample, ours_calib, ours_calib, finetune_calib, k0_finetune_calib))\n",
    "        \n",
    "        # make_calibration_plots(base_calib, k0_calib, oracle_calib, ours_calib, finetune_calib, k0_finetune_calib, data_sample)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # This is the inference call that internally updates L_n and K_n.\n",
    "        adaptive_trajectron.adaptive_predict(\n",
    "            online_batch,\n",
    "            update_mode=UpdateMode.ITERATIVE\n",
    "        )\n",
    "    \n",
    "    if data_sample < 101:\n",
    "        with torch.no_grad():\n",
    "            adaptive_finetune_trajectron.adaptive_predict(\n",
    "                online_batch,\n",
    "                update_mode=UpdateMode.ITERATIVE\n",
    "            )\n",
    "    else:\n",
    "        finetune_update(adaptive_finetune_trajectron, online_batch, update_mode=UpdateMode.NO_UPDATE)\n",
    "\n",
    "    finetune_update(finetune_trajectron, online_batch)\n",
    "    finetune_last_layer_update(k0_finetune_trajectron, online_batch)\n",
    "    \n",
    "    if (data_sample + 1) % 100 == 0:    \n",
    "        ours_calib = compute_calibration_values(adaptive_trajectron, batch_eval_dataloader)\n",
    "        ours_finetune_calib = compute_calibration_values(adaptive_finetune_trajectron, batch_eval_dataloader)\n",
    "        finetune_calib = compute_calibration_values(finetune_trajectron, batch_eval_dataloader)\n",
    "        k0_finetune_calib = compute_calibration_values(k0_finetune_trajectron, batch_eval_dataloader)\n",
    "        \n",
    "        calib_values.append((data_sample, ours_calib, ours_finetune_calib, finetune_calib, k0_finetune_calib))\n",
    "        \n",
    "        # make_calibration_plots(base_calib, k0_calib, oracle_calib, ours_calib, ours_finetune_calib, finetune_calib, k0_finetune_calib, data_sample + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/model_calibrations.pkl\", 'wb') as f:\n",
    "    pickle.dump(calib_values, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
