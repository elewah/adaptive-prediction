{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.widget-area { display: none !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured environment to avoid widget CDN issues\n"
     ]
    }
   ],
   "source": [
    "# Fix for widget CDN error: Configure tqdm to use plain text instead of widgets\n",
    "import os\n",
    "os.environ[\"TQDM_DISABLE\"] = \"0\"  # Enable tqdm but force plain text\n",
    "\n",
    "# Force tqdm to use plain text progress bars instead of widgets\n",
    "import tqdm\n",
    "tqdm.tqdm._instances.clear()  # Clear any existing widget instances\n",
    "\n",
    "# Also disable ipywidgets if causing issues\n",
    "try:\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(\"<style>.widget-area { display: none !important; }</style>\"))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Configured environment to avoid widget CDN issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Widget CDN Error Solutions\n",
    "\n",
    "The error \"Failed to access CDN https://unpkg.com/\" occurs when Jupyter widgets try to load resources from the internet but fail due to network issues. Here are several solutions:\n",
    "\n",
    "### Solution 1: âœ… Use console tqdm (Applied above)\n",
    "- Changed `from tqdm.notebook import tqdm` to `from tqdm import tqdm`\n",
    "- Added environment configuration to force plain text progress bars\n",
    "\n",
    "### Alternative Solutions (if needed):\n",
    "\n",
    "**Solution 2: Install jupyter-widgets locally**\n",
    "```bash\n",
    "pip install --upgrade ipywidgets\n",
    "jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "```\n",
    "\n",
    "**Solution 3: Disable widgets completely**\n",
    "```python\n",
    "import os\n",
    "os.environ['TQDM_DISABLE'] = '1'  # Completely disable tqdm\n",
    "```\n",
    "\n",
    "**Solution 4: Use jupyter lab extensions**\n",
    "```bash\n",
    "jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "```\n",
    "\n",
    "**Solution 5: Offline widget setup**\n",
    "```bash\n",
    "pip install jupyter-widgets-static\n",
    "```\n",
    "\n",
    "The current notebook is configured to use console-based progress bars instead of widgets to avoid CDN connectivity issues."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Adaptive Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import trajectron.visualization as visualization\n",
    "import trajdata.visualization.vis as trajdata_vis\n",
    "\n",
    "from torch import optim, nn\n",
    "from torch.utils import data\n",
    "from trajdata.data_structures.data_index import AgentDataIndex\n",
    "from tqdm import tqdm  # Use console version instead of notebook widgets\n",
    "from trajectron.model.model_registrar import ModelRegistrar\n",
    "from trajectron.model.model_utils import UpdateMode\n",
    "from trajectron.model.trajectron import Trajectron\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, Final, List, Optional\n",
    "from trajdata import UnifiedDataset, AgentType, AgentBatch\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to suit your computing environment and folder structure!\n",
    "\n",
    "# TRAJDATA_CACHE_DIR: Final[str] = \"/home/bivanovic/.unified_data_cache\"\n",
    "# LYFT_SAMPLE_RAW_DATA_DIR: Final[str] = \"/home/bivanovic/datasets/lyft/scenes/sample.zarr\"\n",
    "\n",
    "TRAJDATA_CACHE_DIR: Final[str] = \"/home/iot-lab/.unified_data_cache\"\n",
    "LYFT_SAMPLE_RAW_DATA_DIR: Final[str] = \"/home/iot-lab/datasets/nuScenes\"\n",
    "sample_type=\"nusc_mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"models/nusc_mm_base_tpp-11_Sep_2022_19_15_45\"\n",
    "k0_model = \"models/nusc_mm_k0_tpp-12_Sep_2022_00_40_16\"\n",
    "adaptive_model = \"models/nusc_mm_sec4_tpp-13_Sep_2022_11_06_01\"\n",
    "oracle_model = \"models/lyft_mm_base_tpp-11_Sep_2022_18_56_49\"\n",
    "\n",
    "base_checkpoint = 20\n",
    "k0_checkpoint = 20\n",
    "adaptive_checkpoint = 20\n",
    "oracle_checkpoint = 1\n",
    "\n",
    "eval_data = \"nusc_mini-mini_val\"\n",
    "\n",
    "history_sec = 1.0\n",
    "prediction_sec = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "AXHLINE_COLORS = {\n",
    "    \"Base\": \"#DD9787\",\n",
    "    \"K0\": \"#A6C48A\",\n",
    "    \"Oracle\": \"#BCB6FF\"\n",
    "}\n",
    "\n",
    "SEABORN_PALETTE = {\n",
    "    \"Finetune\": \"#AA7C85\",\n",
    "    \"K0+Finetune\": \"#2D93AD\",\n",
    "    \"Ours\": \"#67934D\",\n",
    "    \"Ours+Finetune\": \"#FF8E61\",\n",
    "    \"Base\": \"#DD9787\",\n",
    "    \"K0\": \"#A6C48A\",\n",
    "    \"Oracle\": \"#BCB6FF\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir: str, device: str, epoch: int = 10, custom_hyperparams: Optional[Dict] = None):\n",
    "    save_path = Path(model_dir) / f'model_registrar-{epoch}.pt'\n",
    "\n",
    "    model_registrar = ModelRegistrar(model_dir, device)\n",
    "    with open(os.path.join(model_dir, 'config.json'), 'r') as config_json:\n",
    "        hyperparams = json.load(config_json)\n",
    "        \n",
    "    if custom_hyperparams is not None:\n",
    "        hyperparams.update(custom_hyperparams)\n",
    "\n",
    "    trajectron = Trajectron(model_registrar, hyperparams, None, device)\n",
    "    trajectron.set_environment()\n",
    "    trajectron.set_annealing_params()\n",
    "\n",
    "    checkpoint = torch.load(save_path, map_location=device)\n",
    "    trajectron.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "\n",
    "    return trajectron, hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_to_predchal(\n",
    "    dataset: UnifiedDataset,\n",
    "    split: str\n",
    ") -> None:\n",
    "    with open(f'predchal_{split}_index.pkl','rb') as f:\n",
    "        within_challenge_split = pickle.load(f)\n",
    "    \n",
    "    within_challenge_split = [\n",
    "        (dataset.cache_path / scene_info_path, num_elems, elems)\n",
    "        for scene_info_path, num_elems, elems in within_challenge_split\n",
    "    ]\n",
    "    \n",
    "    dataset._scene_index = [orig_path for orig_path, _, _ in within_challenge_split]\n",
    "\n",
    "    # The data index is effectively a big list of tuples taking the form:\n",
    "    # (scene_path: str, index_len: int, valid_timesteps: np.ndarray[, agent_name: str])\n",
    "    dataset._data_index = AgentDataIndex(within_challenge_split, dataset.verbose)\n",
    "    dataset._data_len: int = len(dataset._data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_update(model: Trajectron, batch: AgentBatch = None, dataloader: data.DataLoader = None, num_epochs: int = None, update_mode: UpdateMode = UpdateMode.NO_UPDATE) -> float:\n",
    "    if batch is None and dataloader is None:\n",
    "        raise ValueError(\"Only one of batch or dataloader can be passed in.\")\n",
    "    \n",
    "    if dataloader is not None and num_epochs is None:\n",
    "        raise ValueError(\"num_epochs must not be None if dataloader is not None.\")\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    optimizer = optim.Adam([{'params': model.model_registrar.get_all_but_name_match('map_encoder').parameters()},\n",
    "                            {'params': model.model_registrar.get_name_match('map_encoder').parameters(),\n",
    "                             'lr': model.hyperparams['map_enc_learning_rate']/10}],\n",
    "                           lr=model.hyperparams['learning_rate']/10)\n",
    "    # Set Learning Rate\n",
    "    if model.hyperparams['learning_rate_style'] == 'const':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.0)\n",
    "    elif model.hyperparams['learning_rate_style'] == 'exp':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                        gamma=model.hyperparams['learning_decay_rate'])\n",
    "    \n",
    "    if batch is not None:\n",
    "        model.step_annealers()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        train_loss = model(batch, update_mode=update_mode)\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Clipping gradients.\n",
    "        if model.hyperparams['grad_clip'] is not None:\n",
    "            nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Stepping forward the learning rate scheduler and annealers.\n",
    "        lr_scheduler.step()\n",
    "    \n",
    "    elif dataloader is not None:\n",
    "        batch: AgentBatch\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            model.step_annealers()\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            train_loss = model(batch)\n",
    "                        \n",
    "            train_loss.backward()\n",
    "\n",
    "            # Clipping gradients.\n",
    "            if model.hyperparams['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Stepping forward the learning rate scheduler and annealers.\n",
    "            lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_last_layer_update(model: Trajectron, batch: AgentBatch = None, dataloader: data.DataLoader = None, num_epochs: int = None) -> float:\n",
    "    if batch is None and dataloader is None:\n",
    "        raise ValueError(\"Only one of batch or dataloader can be passed in.\")\n",
    "    \n",
    "    if dataloader is not None and num_epochs is None:\n",
    "        raise ValueError(\"num_epochs must not be None if dataloader is not None.\")\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    optimizer = optim.Adam([{'params': model.model_registrar.get_all_but_name_match('last_layer').parameters()},\n",
    "                            {'params': model.model_registrar.get_name_match('last_layer').parameters(),\n",
    "                             'lr': model.hyperparams['learning_rate']/10}],\n",
    "                           lr=0)\n",
    "    # Set Learning Rate\n",
    "    if model.hyperparams['learning_rate_style'] == 'const':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=1.0)\n",
    "    elif model.hyperparams['learning_rate_style'] == 'exp':\n",
    "        lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                        gamma=model.hyperparams['learning_decay_rate'])\n",
    "    \n",
    "    if batch is not None:\n",
    "        model.step_annealers()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        train_loss = model(batch)\n",
    "        train_loss.backward()\n",
    "\n",
    "        # Clipping gradients.\n",
    "        if model.hyperparams['grad_clip'] is not None:\n",
    "            nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Stepping forward the learning rate scheduler and annealers.\n",
    "        lr_scheduler.step()\n",
    "            \n",
    "    elif dataloader is not None:\n",
    "        batch: AgentBatch\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            model.step_annealers()\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            train_loss = model(batch)\n",
    "                        \n",
    "            train_loss.backward()\n",
    "\n",
    "            # Clipping gradients.\n",
    "            if model.hyperparams['grad_clip'] is not None:\n",
    "                nn.utils.clip_grad_value_(model.model_registrar.parameters(), model.hyperparams['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Stepping forward the learning rate scheduler and annealers.\n",
    "            lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['boston-nusc_mini-mini_val', 'nusc_mini-singapore-mini_val']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Agent Data (Serially): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15797.76it/s]\n",
      "Calculating Agent Data (Serially): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15797.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 901.71it/s]\n",
      "Creating Agent Data Index (Serially): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 901.71it/s]\n",
      "Structuring Agent Data Index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 1916.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['boston-nusc_mini-mini_val', 'nusc_mini-singapore-mini_val']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Agent Data (Serially): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 7115.02it/s]\n",
      "Calculating Agent Data (Serially): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 7115.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 420.02it/s]\n",
      "Structuring Agent Data Index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 2050.00it/s]\n",
      "Creating Agent Data Index (Serially): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 420.02it/s]\n",
      "Structuring Agent Data Index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 2050.00it/s]\n"
     ]
    }
   ],
   "source": [
    "adaptive_trajectron, hyperparams = load_model(\n",
    "    adaptive_model, device, epoch=adaptive_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": True}\n",
    ")\n",
    "# For offline test\n",
    "adaptive_finetune_trajectron, _ = load_model(\n",
    "    adaptive_model, device, epoch=adaptive_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": True}\n",
    ")\n",
    "\n",
    "\n",
    "k0_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "k0_finetune_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "base_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "finetune_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "oracle_trajectron, _ = load_model(oracle_model, device, epoch=oracle_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "# Load training and evaluation environments and scenes\n",
    "attention_radius = defaultdict(lambda: 20.0) # Default range is 20m unless otherwise specified.\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.PEDESTRIAN)] = 10.0\n",
    "attention_radius[(AgentType.PEDESTRIAN, AgentType.VEHICLE)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.PEDESTRIAN)] = 20.0\n",
    "attention_radius[(AgentType.VEHICLE, AgentType.VEHICLE)] = 30.0\n",
    "\n",
    "map_params = {\"px_per_m\": 2, \"map_size_px\": 100, \"offset_frac_xy\": (-0.75, 0.0)}\n",
    "\n",
    "online_eval_dataset = UnifiedDataset(\n",
    "    desired_data=[eval_data],\n",
    "    history_sec=(0.1, history_sec),\n",
    "    future_sec=(prediction_sec, prediction_sec),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams['incl_robot_node'],\n",
    "    incl_raster_map=hyperparams['map_encoding'],\n",
    "    raster_map_params=map_params,\n",
    "    only_predict=[AgentType.VEHICLE],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=0,\n",
    "    cache_location=TRAJDATA_CACHE_DIR,\n",
    "    data_dirs={\n",
    "        sample_type: LYFT_SAMPLE_RAW_DATA_DIR,\n",
    "    },\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "batch_eval_dataset = UnifiedDataset(\n",
    "    desired_data=[eval_data],\n",
    "    history_sec=(history_sec, history_sec),\n",
    "    future_sec=(prediction_sec, prediction_sec),\n",
    "    agent_interaction_distances=attention_radius,\n",
    "    incl_robot_future=hyperparams['incl_robot_node'],\n",
    "    incl_raster_map=hyperparams['map_encoding'],\n",
    "    raster_map_params=map_params,\n",
    "    only_predict=[AgentType.VEHICLE],\n",
    "    no_types=[AgentType.UNKNOWN],\n",
    "    num_workers=0,\n",
    "    cache_location=TRAJDATA_CACHE_DIR,\n",
    "    data_dirs={\n",
    "        sample_type: \"\",\n",
    "    },\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = re.compile(\"(.*)/(?P<scene_name>.*)/(.*)$\")\n",
    "\n",
    "def plot_outputs(\n",
    "    eval_dataset: UnifiedDataset,\n",
    "    dataset_idx: int,\n",
    "    model: Trajectron,\n",
    "    model_name: str,\n",
    "    agent_ts: int,\n",
    "    save=True,\n",
    "    extra_str=None,\n",
    "    subfolder=\"\",\n",
    "    filetype=\"png\"\n",
    "):\n",
    "    batch: AgentBatch = eval_dataset.get_collate_fn(pad_format=\"right\")([eval_dataset[dataset_idx]])\n",
    "    with torch.no_grad():\n",
    "        # predictions = model.predict(batch,\n",
    "        #                             z_mode=True,\n",
    "        #                             gmm_mode=True,\n",
    "        #                             full_dist=False,\n",
    "        #                             output_dists=False)\n",
    "        # prediction = next(iter(predictions.values()))\n",
    "        \n",
    "        pred_dists, _ = model.predict(batch,\n",
    "                                      z_mode=False,\n",
    "                                      gmm_mode=False,\n",
    "                                      full_dist=True,\n",
    "                                      output_dists=True)\n",
    "        # pred_dist = next(iter(pred_dists.values()))\n",
    "        \n",
    "    batch.to(\"cpu\")\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    trajdata_vis.plot_agent_batch(batch, batch_idx=0, ax=ax, show=False, close=False)\n",
    "    visualization.visualize_distribution(ax, pred_dists, batch_idx=0)\n",
    "    \n",
    "    # batch_eval: Dict[str, torch.Tensor] = evaluation.compute_batch_statistics_pt(\n",
    "    #     batch.agent_fut[..., :2],\n",
    "    #     prediction_output_dict=torch.from_numpy(prediction),\n",
    "    #     y_dists=pred_dist\n",
    "    # )\n",
    "    \n",
    "    scene_info_path, _, scene_ts = eval_dataset._data_index[dataset_idx]\n",
    "    scene_name = prog.match(scene_info_path).group(\"scene_name\")\n",
    "    \n",
    "    agent_name = batch.agent_name[0]\n",
    "    agent_type_name = f\"{str(AgentType(batch.agent_type[0].item()))}/{agent_name}\"\n",
    "    \n",
    "    ax.set_title(f\"{scene_name}/t={scene_ts} {agent_type_name}\")\n",
    "    # print(model_name, extra_str, batch_eval)\n",
    "    \n",
    "    if save:\n",
    "        fname = f\"plots/{subfolder}{model_name}_{scene_name}_{agent_name}_t{agent_ts}\"\n",
    "        if extra_str:\n",
    "            fname += \"_\" + extra_str\n",
    "        fig.savefig(fname + f\".{filetype}\")\n",
    "        \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(\n",
    "    eval_dataset: UnifiedDataset,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 0,\n",
    "    shuffle: bool = False\n",
    "):\n",
    "    return data.DataLoader(\n",
    "        eval_dataset,\n",
    "        collate_fn=eval_dataset.get_collate_fn(pad_format=\"right\"),\n",
    "        pin_memory=False if device == 'cpu' else True,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [\"ml_ade\", \"ml_fde\", \"nll_mean\", \"min_ade_5\", \"min_ade_10\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Online (Per-Agent) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_results_to_summary(\n",
    "    model_name: str,\n",
    "    overall_summary_dict: Dict[str, List[float]],\n",
    "    model_perf_dict: Dict[AgentType, Dict[str, np.ndarray]]\n",
    "):\n",
    "    overall_summary_dict[\"model\"].append(model_name)\n",
    "    for metric in metrics_list:\n",
    "        overall_summary_dict[metric].append(np.mean(np.concatenate(model_perf_dict[AgentType.VEHICLE][metric])).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval Base: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:13<00:00,  1.26it/s]\n",
      "Eval Base: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:13<00:00,  1.26it/s]\n",
      "Eval K0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "Eval K0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:13<00:00,  2.49it/s]\n",
      "Eval Oracle: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:13<00:00,  1.23it/s]\n",
      "Eval Oracle: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:13<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_dict = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Base Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=16)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval Base'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = base_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "    \n",
    "    add_results_to_summary(\"Base\", eval_dict, model_perf)\n",
    "    \n",
    "    # K0 Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, batch_size=64, num_workers=8)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval K0'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = k0_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "                \n",
    "    add_results_to_summary(\"K0\", eval_dict, model_perf)\n",
    "    \n",
    "    # Oracle Model\n",
    "    batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "    model_perf = defaultdict(lambda: defaultdict(list))\n",
    "    for eval_batch in tqdm(batch_eval_dataloader, desc=f'Eval Oracle'):\n",
    "        eval_results: Dict[AgentType, Dict[str, torch.Tensor]] = oracle_trajectron.predict_and_evaluate_batch(eval_batch)\n",
    "        for agent_type, metric_dict in eval_results.items():\n",
    "            for metric, values in metric_dict.items():\n",
    "                model_perf[agent_type][metric].append(values.cpu().numpy())\n",
    "                \n",
    "    add_results_to_summary(\"Oracle\", eval_dict, model_perf)\n",
    "    \n",
    "    del eval_batch\n",
    "    del eval_results\n",
    "    del model_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'model': ['Base', 'K0', 'Oracle'],\n",
       "             'ml_ade': [0.7199507355690002,\n",
       "              0.26259008049964905,\n",
       "              0.4440161883831024],\n",
       "             'ml_fde': [1.3890087604522705,\n",
       "              0.481600821018219,\n",
       "              0.7074191570281982],\n",
       "             'nll_mean': [-1.3222638368606567,\n",
       "              0.5856841206550598,\n",
       "              -1.7169257402420044],\n",
       "             'min_ade_5': [0.1929401159286499,\n",
       "              0.16462832689285278,\n",
       "              0.42212653160095215],\n",
       "             'min_ade_10': [0.1210647001862526,\n",
       "              0.13454264402389526,\n",
       "              0.4155721068382263]})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/base_performance.pkl\", 'wb') as f:\n",
    "    pickle.dump(eval_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/base_performance.pkl\", 'rb') as f:\n",
    "    eval_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'model': ['Base', 'K0', 'Oracle'],\n",
       "             'ml_ade': [0.7199507355690002,\n",
       "              0.26259008049964905,\n",
       "              0.4440161883831024],\n",
       "             'ml_fde': [1.3890087604522705,\n",
       "              0.481600821018219,\n",
       "              0.7074191570281982],\n",
       "             'nll_mean': [-1.3222638368606567,\n",
       "              0.5856841206550598,\n",
       "              -1.7169257402420044],\n",
       "             'min_ade_5': [0.1929401159286499,\n",
       "              0.16462832689285278,\n",
       "              0.42212653160095215],\n",
       "             'min_ade_10': [0.1210647001862526,\n",
       "              0.13454264402389526,\n",
       "              0.4155721068382263]})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_calibration_values(model: Trajectron, dataloader: data.DataLoader):\n",
    "    est_probs = list()\n",
    "    \n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        batch.to(model.device)\n",
    "        \n",
    "        node_type: AgentType\n",
    "        for node_type in batch.agent_types():\n",
    "            mgcvae = model.node_models_dict[node_type.name]\n",
    "\n",
    "            agent_type_batch = batch.for_agent_type(node_type)\n",
    "            ph = agent_type_batch.agent_fut.shape[1]\n",
    "\n",
    "            # Run forward pass\n",
    "            y_dists, _ = mgcvae.predict(agent_type_batch,\n",
    "                                        prediction_horizon=ph,\n",
    "                                        num_samples=1,\n",
    "                                        z_mode=False,\n",
    "                                        gmm_mode=False,\n",
    "                                        full_dist=True,\n",
    "                                        output_dists=True)\n",
    "            \n",
    "            estimated_prob = y_dists.quantile(batch.agent_fut[..., :2])\n",
    "            est_probs.extend(estimated_prob.flatten().tolist())\n",
    "    \n",
    "    return np.asarray(est_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "calib_values = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    base_calib = compute_calibration_values(base_trajectron, get_dataloader(batch_eval_dataset, num_workers=16))\n",
    "\n",
    "    batch_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "    k0_calib = compute_calibration_values(k0_trajectron, batch_dataloader)\n",
    "    oracle_calib = compute_calibration_values(oracle_trajectron, batch_dataloader)\n",
    "\n",
    "calib_values.append((0, base_calib, k0_calib, oracle_calib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_plot(est_gt_probs: np.ndarray, method_name: str, ax):\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    \n",
    "    num_gt_points = est_gt_probs.shape[0]\n",
    "    # Commenting this out, although it could be used to scale to the max PDF height.\n",
    "    # No need though, without it we can see overconfidence easier.\n",
    "    # max_pdf = est_gt_probs.max()\n",
    "    \n",
    "    fraction_gt_included = [(est_gt_probs >= threshold).sum() / num_gt_points for threshold in thresholds]\n",
    "    \n",
    "    ax.plot(thresholds, fraction_gt_included, label=method_name, lw=3, c=SEABORN_PALETTE[method_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_calibration_plots(base_calib, k0_calib, oracle_calib, ours_calib, ours_finetune_calib, finetune_calib, k0_finetune_calib, num_updates):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot([0, 1], [1, 0], label=\"Ideal\", ls=\"--\", c=\"k\")\n",
    "\n",
    "    calibration_plot(base_calib, \"Base\", ax)\n",
    "    calibration_plot(k0_calib, \"K0\", ax)\n",
    "    calibration_plot(oracle_calib, \"Oracle\", ax)\n",
    "    calibration_plot(ours_finetune_calib, \"Ours+Finetune\", ax)\n",
    "    calibration_plot(ours_calib, \"Ours\", ax)\n",
    "    calibration_plot(finetune_calib, \"Finetune\", ax)\n",
    "    calibration_plot(k0_finetune_calib, \"K0+Finetune\", ax)\n",
    "\n",
    "    ax.legend(bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0)\n",
    "    ax.set_xlabel(\"Probability Threshold\")\n",
    "    ax.set_ylabel(\"Fraction of GT Points\")\n",
    "\n",
    "    ax.grid(False)\n",
    "    \n",
    "    # fig.savefig(f\"results/calib_after{num_updates}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adaptive Eval PH=2.0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:43<00:00,  4.38s/it]\n",
      "Adaptive Eval PH=2.0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:43<00:00,  4.38s/it]\n"
     ]
    }
   ],
   "source": [
    "online_eval_dataloader = get_dataloader(online_eval_dataset, batch_size=1, shuffle=True)\n",
    "batch_eval_dataloader = get_dataloader(batch_eval_dataset, num_workers=8)\n",
    "\n",
    "adaptive_trajectron.reset_adaptive_info()\n",
    "adaptive_finetune_trajectron.reset_adaptive_info()\n",
    "\n",
    "# Resetting the finetune baselines to their base.\n",
    "finetune_trajectron, _ = load_model(base_model, device, epoch=base_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "k0_finetune_trajectron, _ = load_model(k0_model, device, epoch=k0_checkpoint,\n",
    "    custom_hyperparams={\"trajdata_cache_dir\": TRAJDATA_CACHE_DIR,\n",
    "                        \"single_mode_multi_sample\": False})\n",
    "\n",
    "N_SAMPLES = 10\n",
    "\n",
    "outer_pbar = tqdm(\n",
    "    online_eval_dataloader,\n",
    "    total=min(N_SAMPLES, len(online_eval_dataloader)),\n",
    "    desc=f'Adaptive Eval PH={prediction_sec}',\n",
    "    position=0,\n",
    ")\n",
    "\n",
    "plot_per_eval = False\n",
    "\n",
    "online_batch: AgentBatch\n",
    "for data_sample, online_batch in enumerate(outer_pbar):\n",
    "    if data_sample >= N_SAMPLES:\n",
    "        outer_pbar.close()\n",
    "        break\n",
    "    \n",
    "    if data_sample == 0:\n",
    "        ours_calib = compute_calibration_values(adaptive_trajectron, batch_eval_dataloader)\n",
    "        finetune_calib = compute_calibration_values(finetune_trajectron, batch_eval_dataloader)\n",
    "        k0_finetune_calib = compute_calibration_values(k0_finetune_trajectron, batch_eval_dataloader)\n",
    "        \n",
    "        calib_values.append((data_sample, ours_calib, ours_calib, finetune_calib, k0_finetune_calib))\n",
    "        \n",
    "        # make_calibration_plots(base_calib, k0_calib, oracle_calib, ours_calib, finetune_calib, k0_finetune_calib, data_sample)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # This is the inference call that internally updates L_n and K_n.\n",
    "        adaptive_trajectron.adaptive_predict(\n",
    "            online_batch,\n",
    "            update_mode=UpdateMode.ITERATIVE\n",
    "        )\n",
    "    \n",
    "    if data_sample < 101:\n",
    "        with torch.no_grad():\n",
    "            adaptive_finetune_trajectron.adaptive_predict(\n",
    "                online_batch,\n",
    "                update_mode=UpdateMode.ITERATIVE\n",
    "            )\n",
    "    else:\n",
    "        finetune_update(adaptive_finetune_trajectron, online_batch, update_mode=UpdateMode.NO_UPDATE)\n",
    "\n",
    "    finetune_update(finetune_trajectron, online_batch)\n",
    "    finetune_last_layer_update(k0_finetune_trajectron, online_batch)\n",
    "    \n",
    "    if (data_sample + 1) % 100 == 0:    \n",
    "        ours_calib = compute_calibration_values(adaptive_trajectron, batch_eval_dataloader)\n",
    "        ours_finetune_calib = compute_calibration_values(adaptive_finetune_trajectron, batch_eval_dataloader)\n",
    "        finetune_calib = compute_calibration_values(finetune_trajectron, batch_eval_dataloader)\n",
    "        k0_finetune_calib = compute_calibration_values(k0_finetune_trajectron, batch_eval_dataloader)\n",
    "        \n",
    "        calib_values.append((data_sample, ours_calib, ours_finetune_calib, finetune_calib, k0_finetune_calib))\n",
    "        \n",
    "        # make_calibration_plots(base_calib, k0_calib, oracle_calib, ours_calib, ours_finetune_calib, finetune_calib, k0_finetune_calib, data_sample + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/model_calibrations.pkl\", 'wb') as f:\n",
    "    pickle.dump(calib_values, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
